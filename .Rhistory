train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE)
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent ,
data = atx,
trControl = train_control,
method = "glm",
family=binomial(),
returnData = TRUE
)
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE)
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent ,
data = atx,
trControl = train_control,
method = "glm",
family=binomial(),
returnResamp = "all"
)
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE, returnData = TRUE)
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent ,
data = atx,
trControl = train_control,
method = "glm",
family=binomial()
)
# print cv scores
print(model)
print(model$resample)
View(model)
model$results
model$resample
model$resampleCM
model$trainingData
model$modelInfo
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE, returnData = TRUE, returnResamp = "all")
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent ,
data = atx,
trControl = train_control,
method = "glm",
family=binomial()
)
# print cv scores
print(model)
print(model$resample)
View(model)
model$trainingData
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE, returnData = TRUE, returnResamp = "all",
summaryFunction = twoClassSummary)
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent ,
data = atx,
trControl = train_control,
method = "glm",
family=binomial()
)
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE, returnData = TRUE, returnResamp = "all")
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent ,
data = atx,
trControl = train_control,
method = "glm",
family=binomial()
)
# print cv scores
print(model)
print(model$resample)
?trainControl
View(train_control)
View(model)
model$trainingData
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE)
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income,
data = atx,
trControl = train_control,
method = "glm",
family=binomial()
)
# print cv scores
print(model)
print(model$resample)
# Define training control
set.seed(2)
train_control <- trainControl(method = "cv", number = 5, verboseIter = TRUE)
# train the model on training set
model <- train(hi_use ~ customer_class + median_home_value + median_household_income + median_rent,
data = atx,
trControl = train_control,
method = "glm",
family=binomial()
)
# print cv scores
print(model)
print(model$resample)
2^2
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,e,y)
View(df)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point()
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 55, linetype = "dashed", color = "red")
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 55, linetype = "dashed", color = "red")
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 54.2857143, linetype = "dashed", color = "red")
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 54.2857143, color = "red")
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 54.2857143, linetype = "dashed", color = "red")
model <- lm(y ~ x1 + poly(x1,degree=2), data = df)
model <- lm(y ~ x1 + poly(x1,degree=2), data = df)
summary(model)
install.packages("boot")
install.packages("boot")
?boot
library(boot)
?boot
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 54.2857143, linetype = "dashed", color = "red")
library(ggplot2)
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 54.2857143, linetype = "dashed", color = "red")
library(boot)
model <- lm(y ~ x1 + poly(x1,degree=2), data = df)
summary(model)
alpha.fn=function(data,index){
X=data$x1[index]
Y=data$Y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(Portfolio ,1:100)
alpha.fn=function(data,index){
X=data$x1[index]
Y=data$Y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(df ,1:100)
alpha.fn=function(data,index){
X=data$x1[index]
Y=data$y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(df ,1:100)
alpha.fn=function(data,index){
X=data$x1[index]
Y=data$y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(df ,1:100)
boot(data = df, statistic = alpha.fn, R = 1000)
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=train)
summary(model)
library(caret)
p <- predict(model, test, type = "response")
print(summary(p))
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["hi_use"]]))
set.seed(2)
split = sample.split(atx$hi_use, SplitRatio = 0.80)
library(reshape2)
library(readr)
library(janitor)
library(dplyr)
water <- read_csv("Austin_Water_-_Residential_Water_Consumption.csv")
water <- clean_names(water)
water$customer_class <- gsub(" - ", "_", water$customer_class)
water$customer_class <- gsub("-", "_", water$customer_class)
water$year <- as.numeric(substr(water$year_month, 1, 4))
water$month <- as.numeric(substr(water$year_month, 5, 6))
water <- water[water$postal_code != "", ]
water <- na.omit(water)
water <- as.data.frame(aggregate(data=water, total_gallons~customer_class+year+postal_code, sum))
water <- water[water$year == 2014,]
water$hi_use <- 0
water$hi_use[water$total_gallons > mean(water$total_gallons)] = 1
water$zip_code <- water$postal_code
houses <- read_csv("2014_Housing_Market_Analysis_Data_by_Zip_Code.csv")
houses <- clean_names(houses)
atx <- inner_join(water, houses, by="zip_code")
atx$hi_use <- as.factor(atx$hi_use)
library(caTools)
set.seed(555)
split = sample.split(atx$hi_use, SplitRatio = 0.80)
train = subset(atx, split == TRUE)
test = subset(atx, split == FALSE)
print(summary(train$hi_use))
print(summary(test$hi_use))
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=train)
summary(model)
library(caret)
p <- predict(model, test, type = "response")
print(summary(p))
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["hi_use"]]))
set.seed(2)
split = sample.split(atx$hi_use, SplitRatio = 0.80)
train = subset(atx, split == TRUE)
test = subset(atx, split == FALSE)
print(summary(train$hi_use))
print(summary(test$hi_use))
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=train)
summary(model)
p <- predict(model, test, type = "response")
print(summary(p))
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["hi_use"]]))
# Define training control
set.seed(123)
train_control <- trainControl(method = "cv", number = 5)
# train the model on training set
model <- train(hi_use ~ customer_class +median_home_value + median_household_income + median_rent ,
data = train,
trControl = train_control,
method = "glm",
family=binomial())
# print cv scores
summary(model)
# Define training control
set.seed(123)
train_control <- trainControl(method = "cv", number = 5)
# train the model on training set
model <- train(hi_use ~ customer_class +median_home_value + median_household_income + median_rent ,
data = train,
trControl = train_control,
method = "glm",
family=binomial())
# print cv scores
summary(model)
print(model$resample)
folds <- createFolds(atx$hi_use, k = 5, list = TRUE, returnTrain = TRUE)
View(folds)
?sample
rand <- sample(nrow(atx))
K1row <- rand[rand %% 5 + 1 == 1]
K2row <- rand[rand %% 5 + 1 == 2]
K3row <- rand[rand %% 5 + 1 == 3]
K4row <- rand[rand %% 5 + 1 == 4]
K5row <- rand[rand %% 5 + 1 == 5]
rand <- sample(nrow(atx))
K1row <- rand[rand %% 5 + 1 == 1]
K2row <- rand[rand %% 5 + 1 == 2]
K3row <- rand[rand %% 5 + 1 == 3]
K4row <- rand[rand %% 5 + 1 == 4]
K5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[k1row,]
rand <- sample(nrow(atx))
K1row <- rand[rand %% 5 + 1 == 1]
K2row <- rand[rand %% 5 + 1 == 2]
K3row <- rand[rand %% 5 + 1 == 3]
K4row <- rand[rand %% 5 + 1 == 4]
K5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[K1row,]
View(k1fold)
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
krow <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[K1row,]
k2fold <- atx[K2row,]
k3fold <- atx[K3row,]
k4fold <- atx[K4row,]
k5fold <- atx[K5row,]
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
krow <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[K1row,]
k2fold <- atx[K2row,]
k3fold <- atx[K3row,]
k4fold <- atx[K4row,]
k5fold <- atx[K5row,]
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
krow <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[K1row,]
k2fold <- atx[K2row,]
k3fold <- atx[K3row,]
k4fold <- atx[K4row,]
k5fold <- atx[K5row,]
print("Summary Statistics for 5 folds")
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[k1row,]
k2fold <- atx[k2row,]
k3fold <- atx[k3row,]
k4fold <- atx[k4row,]
k5fold <- atx[k5row,]
print("Summary Statistics for 5 folds")
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
set.seed(2)
split = sample.split(k1fold$hi_use, SplitRatio = 0.80)
train = subset(k1fold, split == TRUE)
test = subset(k1fold, split == FALSE)
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=train)
p <- predict(model, test, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["hi_use"]]))
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[k1row,]
k2fold <- atx[k2row,]
k3fold <- atx[k3row,]
k4fold <- atx[k4row,]
k5fold <- atx[k5row,]
print("Summary Statistics for 5 folds")
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
set.seed(2)
split = sample.split(k1fold$hi_use, SplitRatio = 0.75)
train = subset(k1fold, split == TRUE)
test = subset(k1fold, split == FALSE)
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=train)
p <- predict(model, test, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["hi_use"]]))
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[k1row,]
k2fold <- atx[k2row,]
k3fold <- atx[k3row,]
k4fold <- atx[k4row,]
k5fold <- atx[k5row,]
print("Summary Statistics for 5 folds")
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
set.seed(2)
split = sample.split(k1fold$hi_use, SplitRatio = 0.65)
train = subset(k1fold, split == TRUE)
test = subset(k1fold, split == FALSE)
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=train)
p <- predict(model, test, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["hi_use"]]))
?cbind
rbind(k2fold,k3fold, k4fold)
set.seed(2)
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[k1row,]
k2fold <- atx[k2row,]
k3fold <- atx[k3row,]
k4fold <- atx[k4row,]
k5fold <- atx[k5row,]
print("Summary Statistics for 5 folds")
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=rbind(k2fold, k3fold,k4fold,k5fold))
p <- predict(model, k1fold, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, k1fold[["hi_use"]]))
set.seed(2)
rand <- sample(nrow(atx))
k1row <- rand[rand %% 5 + 1 == 1]
k2row <- rand[rand %% 5 + 1 == 2]
k3row <- rand[rand %% 5 + 1 == 3]
k4row <- rand[rand %% 5 + 1 == 4]
k5row <- rand[rand %% 5 + 1 == 5]
k1fold <- atx[k1row,]
k2fold <- atx[k2row,]
k3fold <- atx[k3row,]
k4fold <- atx[k4row,]
k5fold <- atx[k5row,]
print("Summary Statistics for 5 folds")
summary(k1fold$hi_use)
summary(k2fold$hi_use)
summary(k3fold$hi_use)
summary(k4fold$hi_use)
summary(k5fold$hi_use)
#model with k1fold as test
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=rbind(k2fold, k3fold,k4fold,k5fold))
p <- predict(model, k1fold, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, k1fold[["hi_use"]]))
#model with k2fold as test
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=rbind(k1fold, k3fold,k4fold,k5fold))
p <- predict(model, k2fold, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, k2fold[["hi_use"]]))
#Model with k3fold as test
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k4fold,k5fold))
p <- predict(model, k3fold, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, k3fold[["hi_use"]]))
#Model with k4fold as test
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k3fold,k5fold))
p <- predict(model, k4fold, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, k4fold[["hi_use"]]))
#Model with k5fold as test
model <- glm(hi_use~ customer_class +median_home_value + median_household_income + median_rent ,family=binomial(link='logit'),data=rbind(k2fold, k1fold,k3fold,k4fold))
p <- predict(model, k5fold, type = "response")
p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, k5fold[["hi_use"]]))
p_class
library(ggplot2)
set.seed(666)
x1 <- rnorm(100, 75, 20)
e <- rnorm(100, 0, 7)
y <- 125 + -3.8*x1 + 0.035*x1**2
df <- data.frame(x1,y)
ggplot(data = df, aes(x=x1, y=y)) + geom_point() + geom_vline(xintercept = 54.2857143, linetype = "dashed", color = "red")
library(boot)
model <- lm(y ~ x1 + poly(x1,degree=2), data = df)
summary(model)
alpha.fn=function(data,index){
X=data$x1[index]
Y=data$y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(df ,1:100)
boot(data = df, statistic = alpha.fn, R = 1000)
?model
