dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
View(lasso.mod)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
par(mfrow=c(1,2))
plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
plot_glmnet(lasso.mod, xvar="dev",label=5)
par(mfrow=c(1,2))
plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
plot_glmnet(lasso.mod, xvar="dev",label=5)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
par(mfrow=c(1,2))
plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
# par(mfrow=c(1,2))
# plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
#
# plot_glmnet(lasso.mod, xvar="dev",label=5)
set.seed(1)
#how to choose best lambda
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out, label=TRUE)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
# par(mfrow=c(1,2))
# plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
#
# plot_glmnet(lasso.mod, xvar="dev",label=5)
set.seed(1)
#how to choose best lambda
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out, label=TRUE)
coef(cv.out)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
# par(mfrow=c(1,2))
# plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
#
# plot_glmnet(lasso.mod, xvar="dev",label=5)
set.seed(1)
#how to choose best lambda
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out, label=TRUE)
coef(cv.out)
bestlam=cv.out$lambda.min
bestlam
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
# par(mfrow=c(1,2))
# plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
#
# plot_glmnet(lasso.mod, xvar="dev",label=5)
set.seed(1)
#how to choose best lambda
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out, label=TRUE)
coef(cv.out)
bestlam=cv.out$lambda.min
bestlam
#test MSE associated with this value of ??
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mse= mean((lasso.pred-y.test)^2)
mse
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:15,]
lasso.coef
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)
lasso.coef
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)
lasso.coef
lasso.coef[lasso.coef!=0]
View(lasso.coef)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
par(mfrow=c(1,2))
plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
plot_glmnet(lasso.mod, xvar="dev",label=5)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:15,]
lasso.coef
lasso.coef[lasso.coef!=0]
View(out)
dim(coef(lasso.mod ))
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef
lasso.coef[lasso.coef!=0]
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef
lasso.coef[lasso.coef!=0]
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef[lasso.coef!=0]
max(lasso.coef)
?max
type(lasso.coef)
str(lasso.coef)
pleasE_werk <- data.frame(as.list(lasso.coef))
View(pleasE_werk)
pleasE_werk <- data.frame(as.list(lasso.coef[lasso.coef!=0]))
View(pleasE_werk)
caret::getModelInfo("glmnet")$glmnet$varImp
caret::getModelInfo("glmnet")$lasso.coef$varImp
varImp <- function(object, lambda = NULL, ...) {
## skipping a few lines
beta <- predict(object, s = lambda, type = "coef")
if(is.list(beta)) {
out <- do.call("cbind", lapply(beta, function(x) x[,1]))
out <- as.data.frame(out)
} else out <- data.frame(Overall = beta[,1])
out <- abs(out[rownames(out) != "(Intercept)",,drop = FALSE])
out
}
varImp(out, lambda = out$lambda.min)
library(caret)
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef = lasso.coef[lasso.coef!=0]
names(lasso.coef) <- c('var','val')
lasso.coef %>%
arrange(-abs(val)) %>%
print(.,n=25)
?varImp
library(caret)
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
names(lasso.coef) <- c('var','val')
lasso.coef %>%
arrange(-abs(val)) %>%
print(.,n=25)
library(caret)
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(lasso.coef, scale = FALSE)
library(caret)
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = FALSE)
gbmImp
library(caret)
options(scipen=999)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE)
View(gbmImp)
library(caret)
options(scipen=alpha)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE)
View(gbmImp)
library(caret)
options("scipen")
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE)
gbmImp
library(readr)
library(dplyr)
library(caTools)
set.seed(27)
data <- read_csv("pdb2016bgv8_us_clean (1).csv")
data <- filter(data, data$State_name == "Texas" & data$County_name == "Travis County")
drop_columns <- c("TEA_Update_Leave_CEN_2010", "BILQ_Mailout_count_CEN_2010", "BILQ_Frms_CEN_2010",
"pct_TEA_Update_Leave_CEN_2010", "pct_BILQ_Mailout_count_CEN_2010", "Low_Response_Score",
"Census_Mail_Returns_CEN_2010")
data <- data[ , !(names(data) %in% drop_columns)]
data_noID <- data[9:ncol(data)]
drop_LD_columns <- c("AIAN_LAND", "Tot_Population_CEN_2010", "Females_CEN_2010", "Females_ACS_10_14",
"Pop_65plus_CEN_2010", "Pop_65plus_ACS_10_14", "Non_Inst_GQ_CEN_2010", "Pop_5yrs_Over_ACS_10_14",
"Pop_25yrs_Over_ACS_10_14", "ENG_VW_ACS_10_14", "NonFamily_HHD_CEN_2010", "NonFamily_HHD_ACS_10_14",
"Tot_Prns_in_HHD_CEN_2010", "Tot_Occp_Units_CEN_2010", "Tot_Occp_Units_ACS_10_14", "Tot_Vacant_Units_CEN_2010",
"Tot_Vacant_Units_ACS_10_14", "Owner_Occp_HU_CEN_2010", "Owner_Occp_HU_ACS_10_14",
"Valid_Mailback_Count_CEN_2010", "pct_Females_CEN_2010", "pct_Pop_5yrs_Over_ACS_10_14",
"pct_Not_MrdCple_HHD_CEN_2010", "pct_Vacant_Units_ACS_10_14", "pct_Owner_Occp_HU_CEN_2010",
"pct_TEA_MailOutMailBack_CEN_2010", "pct_Deletes_CEN_2010")
data_noID_noMC <- data_noID [ , !(names(data_noID) %in% drop_LD_columns)]
data_noID_noMC <- data_noID_noMC [, -grep("pct_", colnames(data_noID_noMC))]
split = sample.split(data_noID_noMC$Mail_Return_Rate_CEN_2010, SplitRatio = 0.80)
train = subset(data_noID_noMC, split == TRUE)
test = subset(data_noID_noMC, split == FALSE)
library(glmnet)
library(plotmo)
data_noID_noMC <- na.omit(data_noID_noMC)
grid <- 10^seq(10,-2,length=1000) #these functions automatically plot lambda, so we are going to force it to plot over a range of lambda from 10^10 to 10^-2
x <- model.matrix(Mail_Return_Rate_CEN_2010~.,data_noID_noMC)
y <-data_noID_noMC$Mail_Return_Rate_CEN_2010
train <- sample(1:nrow(x), nrow(x)*.80)
test <- (-train)
y.test <- y[test]
# Checks
dim (x[train,])
length(y[train])
length(y.test)
lasso.mod <-glmnet(x[train,], y[train],alpha=1,lambda = grid)
# glmnet() function standardizes the variables by default so that they are on the same scale.
# If alpha=0 then a ridge regression model is fit, and if alpha=1 then a lasso model is fit.
dim(coef(lasso.mod ))
summary(lasso.mod)
# par(mfrow=c(1,2))
# plot_glmnet(lasso.mod, xvar = "lambda", label = 5)
#
# plot_glmnet(lasso.mod, xvar="dev",label=5)
#how to choose best lambda
set.seed(27)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out, label=TRUE)
coef(cv.out)
bestlam=cv.out$lambda.min
bestlam
#test MSE associated with this value of ??
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mse= mean((lasso.pred-y.test)^2)
library(caret)
options("scipen")
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE)
library(caret)
options("scipen")
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
#lasso.coef = lasso.coef[lasso.coef!=0]
# names(lasso.coef) <- c('var','val')
#
# lasso.coef %>%
#   arrange(-abs(val)) %>%
#   print(.,n=25)
gbmImp <- varImp(out, scale = TRUE, lambda =bestlam )
gbmImp
View(gbmImp)
lasso.coef_no0 = lasso.coef[lasso.coef!=0]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
View(lasso.coef_no0)
gbmImp
View(data_noID_noMC)
View(lasso.coef_no0)
View(lasso.coef_no0)
colnames(lasso.coef_no0)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, X.Intercept:avg_Agg_House_Value_ACSMOE_10_14, factor_key=TRUE)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
View(lasso.coef_no0)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long
View(data_long)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value, abs(value))
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
View(data_long)
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
data_long <- data_long[order(value),]
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
data_long <- data_long[order(absolute_value),]
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
data_long <- data_long[order("absolute_value"),]
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
head(mydf[data_longr(data_long$absolute_value), ])
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
head(data_long[data_long(data_long$absolute_value), ])
library(caret)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:161,]
lasso.coef_no0 = data.frame(as.list(lasso.coef[lasso.coef!=0]))
library(tidyr)
data_long <- gather(lasso.coef_no0, coefficient, value, "X.Intercept.":"avg_Agg_House_Value_ACSMOE_10_14", factor_key=TRUE)
data_long <- mutate(data_long, absolute_value = abs(value))
head(data_long[order(data_long$absolute_value), ])
