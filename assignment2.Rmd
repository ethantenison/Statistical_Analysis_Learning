---
title: 'Assignment 2: Classification'
author: "Ethan Tenison"
date: "2/24/2020"
output: html_document
---

# Q1: Classification 

Residential solar photovoltaics (PV) – the roof-mounted panels that generate electricity – are spreading
throughout Austin. Two key drivers of the individual adoption decision are Wealth in K$, and Attitude on
a scale beween 1-4. Suppose you collect data on a group of Austin homeowners where $X_{1}$ = Wealth in
kdollars $X_{2}$ = Attitude, and Y = whether homeowners adopt solar PV. We fit a logistic regression and produce
estimated coefficients β0 = −6, β1 = 0.05, and β2 = 1.<br />


#### (a) Write out the function.


$log$$\frac{p}{(1-p)}$ = $-6$ + $0.05$$X_{1}$ + $1$$X_{2}$

#### (b) Estimate the probability that a homeowner with Wealth of $40k and an Attitude of 3.5 adopts
 solar PV.

$log$$\frac{p}{(1-p)}$ = $-6$ + $0.05$$(40)$ + $1$$(3.5)$  <br />
$log$$\frac{p}{(1-p)}$ = $-6$ + $2$ + $3.5$  <br />
$log$$\frac{p}{(1-p)}$ = $-0.5$   <br />
$\frac{p}{(1-p)}$ = $exp$$(-0.5)$  <br />
$\frac{p}{(1-p)}$ = $0.60653065971$ <br />
$p$ = $\frac{0.60653065971}{(1+0.60653065971)}$ <br />
$p$ = $37.8$%

#### (c) What Wealth value would the homeowner in part (b) need to have in order to have a 50%
 chance of adopting solar PV?

$log$$\frac{0.5}{(1-0.5)}$ = $-6$ + $0.05$$X_{1}$ + $1$$(3.5)$ <br />
$log$$(1)$ = $-6$ + $0.05$$X_{1}$ + $1$$(3.5)$<br />
$0$ = $-6$ + $0.05$$X_{1}$ + $1$$(3.5)$<br />
$2.5$ = $0.05$$X_{1}$<br />
$X_{1}$ = $50K$<br />

#### (d) What if you added a qualitative variable Tesla_Owner as X3, that indicated whether the
 household owns a Tesla plug-in electric car. Tesla cars are quite expensive, and those with solar
 PV systems benefit considerably from not paying for fuel. Write out the new function. What
 value might you expect for new Tesla_Owner coefficient (β3) in this new function? How might
 you expect β1 and β2 in the NEW function to be different from β1 and β2 in the OLD function?
 <br /><br />
 
$\beta_{3}$ will probably be much larger than $\beta_{1}$ and $\beta_{2}$ because Tesla owners benefit from photovoltaics. The value for $\beta_{1}$ will probably decrease slightly because wealth is correlated with owning a Tesla, and some variation previously assigned to $\beta_{1}$ will be included in $\beta_{3}$. It is unlikely that $\beta_{2}$ will change because attitude towards photovoltacics might not be associated with Tesla ownership. 

#### (e) What is missing from this (admittedly simplified) analysis?

We might include an interaction variable for $X_{1}$ and $X_{3}$. You might also want to include a variable for tax rebates. Not all homeowners may qualify, and that could have a big impact on their decision. Another variable that might be important is the avg price of PV panels, which have been declining.    

# Q2: Classification in data (55 points)

Water use per person in Austin is currently at an historic low, but it can still be an issue – particularly
when we are experience a dry, Texas summer. Please use the Austin Water - Residential Water
Consumption data (https://data.austintexas.gov/Utilities-and-City-Services/Austin-Water-Residential-WaterConsumption/sxk7-7k6z) for this question. Take note – this is a real world data set and as such may not be
clean.
 
```{r cleaning, message = FALSE}
library(dplyr)
library(janitor)
library(reshape2)
df <- read.csv("Austin_Water_-_Residential_Water_Consumption.csv")
df <- clean_names(df)
df$year <- substr(df$year_month, 1, 4)
df$year <- as.numeric(df$year)
df$month <- substr(df$year_month, 5, 6)
df$month <- as.factor(df$month)
df <- dplyr::select(df, -c(year_month))
df$customer_class <- gsub(" - ", "_", df$customer_class)
df <- filter(df, postal_code != "")
df$total_gallons[is.na(df$total_gallons)] <- 0
dfwide <- dcast(data=df, postal_code+month+year~customer_class, value.var= 'total_gallons')
dfwide <- clean_names(dfwide)
df$total_gallons[is.na(df$total_gallons)] <- 0
dfwide[is.na(dfwide)] <- 0


```
#### (a) Produce some numerical and graphical summaries of the Water data. What patterns do you
see? <br /> <br />

Total water consumption declined after water restrictions were introduced in 2018. Irrigation remained basically the same even though these numbers should have declined as well. 
```{r a}
library(ggplot2)
options(scipen=999)
print(summary(dfwide))

total_water <- df %>% group_by(year, customer_class) %>% 
                summarize(total_gallons = sum(total_gallons))

tw <- ggplot(total_water, aes(x=year, y=total_gallons, group=customer_class, color=customer_class)) +
        geom_line()
print(tw)

```

#### (b) Create a binary variable, HiResIrr, that contains a 1 if Irrigation_Residential contains a value
above its mean, and a 0 if Irrigation_Residential contains a value below its mean. Use the full
data set to perform a logistic regression with HiResIrr as the response and other variables as
predictors (besides the original Irrigation_Residential variable). Provide a summary of your
obtained results. Do any of the predictors appear to be statistically significant? If so, which
ones? Does it look like residential irrigation has decreased over the past few years? 
<br /><br />

None of the postal codes were statistically significant, so I removed them.Year, multi-family, and residential were significant and had a positive impact on the probability of HiResIrr being above the mean. For every one unit increase in year is associated with an increase in the log-odds of being above the mean by  0.055649003832. When I converted month to a factor, only the hottest months of the year are significant in the positive direction. Irrigation_multifamily was significant in the negative direction.      
```{r log, warning=FALSE}
library(caTools)
logdf <- dfwide

for (i in 1:length(logdf$irrigation_residential)){
                  if(logdf$irrigation_residential[i] > mean(logdf$irrigation_residential)){        
                    logdf$HiResIrr[i] <- 1               
                  }
                  else if(logdf$irrigation_residential[i] <= mean(logdf$irrigation_residential)){        
                    logdf$HiResIrr[i] <- 0 
                  }
}
set.seed(88)
split = sample.split(logdf$HiResIrr, SplitRatio = 0.75)
logdf <- dplyr::select(logdf, -c(irrigation_residential, postal_code))
train = subset(logdf, split == TRUE)
test = subset(logdf, split == FALSE)

model <- glm(HiResIrr ~.,family=binomial(link='logit'),data=train)
summary(model)

```

#### (c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the
confusion matrix is telling you about the types of mistakes made by logistic regression.<br /><br />

Based on this model, with a threshold of 50%, there is a high number of false positives relative to true positives.Overall it was correct $\frac{48 + 887}{1106}$ =$.84$ of the time. 
```{r confusion_matrix, message = FALSE, warning=FALSE}
library(caret)
p <- predict(model, test, type = "response")
print(summary(p))


p_class <- ifelse(p > 0.5, "Predict 1", "Predict 0")
print(table(p_class, test[["HiResIrr"]]))

```

#### (d) Split the data into a training set (80%) and a test set (20%). Perform KNN with several values of K
and all the variables from (b) in order to predict HiResIrr. What test errors do you obtain? Which
value of K seems to perform the best on this data set? Comment on the sensitivity and
specificity<br /><br />

The highest overall prediction rate was reached at k=5. The sensitivity is, or true positive rate is $0.614$, while the specificity, or true negative is relatively higher at $0.936$ 


```{r KNN, message=FALSE, warning=FALSE}
library(class)
library(gmodels)

dfknn <- dfwide
for (i in 1:length(dfknn$irrigation_residential)){
                  if(dfknn$irrigation_residential[i] > mean(dfknn$irrigation_residential)){        
                    dfknn$HiResIrr[i] <- 1               
                  }
                  else if(dfknn$irrigation_residential[i] <= mean(dfknn$irrigation_residential)){        
                    dfknn$HiResIrr[i] <- 0 
                  }
}

set.seed(88)
dfknn <- dplyr::select(dfknn, -c(irrigation_residential, postal_code))
dmy <- dummyVars(" ~ .", data = dfknn)
dfknn <- data.frame(predict(dmy, newdata = dfknn))
split = sample.split(dfknn$HiResIrr, SplitRatio = 0.8)
train_knn = subset(dfknn, split == TRUE)
train_labels = train_knn[["HiResIrr"]]
train_knn[is.na(train_knn)] <- 0

test_knn = subset(dfknn, split == FALSE)
test_labels = test_knn[["HiResIrr"]]
test_knn[is.na(test_knn)] <- 0


dfknn_prediction = class:knn(train= train_knn, test = test_knn, cl= train_labels, k = 4)
CrossTable(x= test_labels, y= dfknn_prediction, chisq = FALSE)
```

####(e) Perform LDA on the training data in order to predict HiResIrr using all the variables from (b) as
predictors. What is the test error of the model obtained? Comment on the sensitivity and
specificity. <br /><br />

The overall test error is $0.164557$.The Sensitivity of the LDA function is high at $0.9530$, but the specificity is low at $0.2760$.  

```{r LDA, message=FALSE, warning=FALSE}
library(MASS)

fit <- lda(HiResIrr ~ year + irrigation_multi_family + multi_family + residential, data=train)

pred.train <- predict(fit,train)$class
pred.test <- predict(fit,test)$class

mean(pred.train == train$HiResIrr)
mean(pred.test == test$HiResIrr)

confusionMatrix(pred.test, reference = as.factor(test$HiResIrr))

```

#### (f) Perform QDA on the training data in order to predict HiResIrr using all the variables from (b) as
predictors. What is the test error of the model obtained?<br /><br />

The test error for the QDA function was slightly higher than LDA at $0.1708861$
```{r QDA}
fit <- qda(HiResIrr ~ year + irrigation_multi_family + multi_family + residential, data=train)

pred.train <- predict(fit,train)$class
pred.test <- predict(fit,test)$class

mean(pred.train == train$HiResIrr)
mean(pred.test == test$HiResIrr)

confusionMatrix(pred.test, reference = as.factor(test$HiResIrr))
```

# Q3: Classification in simulated data (20 points)<br /><br />


####(a) Create a data frame with Index from 1-1000. In a variable called Class, randomly assign each row
one of c(“a”,”b”,”c”). Draw values of X1 and X2 for each class according to the following:
Class a: X1~N(20, 17), X2~N(25, 12),
Class b: X1~N(50, 22), X2~N(65, 19),
Class c: X1~N(75, 20), X2~N(27, 15).
Plot the data as points with X1 on the X-axis, X2 on the Y-axis, and the color determined by Class (hint:
use ggplot). Draw – by hand – your estimate of the Bayes Decision Boundaries.


```{r simulated_data}
library(ggplot2)
let <- letters[1:3]
df <- data.frame("index" = 1:1000, "class" = sample(let, replace = TRUE, size = 1000))

for (i in 1:length(df$index)){
                  if(df$class[i] == "a"){        
                    df$x1[i] <- rnorm(1, 20, 17)
                    df$x2[i] <- rnorm(1, 25, 12)
                  }
                  else if(df$class[i] == "b"){        
                    df$x1[i] <- rnorm(1, 50, 22)
                    df$x2[i] <- rnorm(1, 65, 19)
                  }
                 else if(df$class[i] == "c"){        
                    df$x1[i] <- rnorm(1, 75, 20)
                    df$x2[i] <- rnorm(1, 27, 15)
                  }
}



ggplot(df, aes(x=x1, y=x2, shape = class, color = class)) + geom_point() + ggtitle("Q3(a) Scatter Plot")

```


#### (b) Use LDA to predict class based on X1 and X2. Plot the predicted classes just as you did in (a).
Comment on the differences between the two plots in Q3, and evaluate your hand drawn Bayes
Decision Boundaries. <br /><br />


```{r lda_simulated}
require(MASS)
require(ggplot2)
require(scales)
require(gridExtra)

set.seed(88)
split = sample.split(df, SplitRatio = 0.75)
train = subset(df, split == TRUE)
test = subset(df, split == FALSE)


fit <- lda(class ~ x1 + x2, data=train)
pred <- predict(fit, test)$class
ggplot(data = test, aes(x1, x2, color=pred)) + geom_point()
ggplot(data = test, aes(x1,x2, color=class)) + geom_point()

ldacorrect = mean(pred == df$class)
ldaerror = 1- ldacorrect
ldaerror

```